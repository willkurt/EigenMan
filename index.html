<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>EigenMan by willkurt</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">


        <h1>Eigen Man</h1>

<img src="https://raw.github.com/willkurt/EigenMan/master/final/eigen_0_large.png"
       alt="Eigen Man" >

        <p>Having fun using Principal Component Analysis and
        Mega Man!<br>
by <a href="https://github.com/willkurt">willkurt</a>
</p>

        <h3>Markov Man and the essence of Mega Man</h3>
<p>
For a long time I’ve been fascinated by how much detail is in simple
sprites from the 8-bit video games I grew up with.  I’d always been
particularly fond of Mega Man.  A few years back I wanted to see if I
could figure out a way to computationally capture the essence of what
all these sprites had in common.  My first experiment was a small
<a href="http://processing.org/">Processing</a> program I called “Markov Man” which used a <a href="http://en.wikipedia.org/wiki/Markov_chain">Markov chain</a> to generate original Mega Man boss sprites from a corpus of 32x32 boss sprites.</p>
<img src="./images/markovman.png" alt="Markov Man" >
<p>As you can see the Markov Man experiment lead to some interesting, but pretty incomprehensible output.
</p>

<h3>Revisiting with computer vision</h3>

<p>
Over the holiday I was gifted a copy
of <a href="http://programmingcomputervision.com/">Programming
    Computer Vision with Python</a>.  I’ve done a fair bit of data
mining/machine learning work recently but have never really taken the
time to learn much in the area of computer vision.  The book starts
out with a great discussion on both principal component analysis and
simply using the mean of a matrix of flattened images in order to
approach the same problem I had looked at years ago.  I also had
previously come across work on <a href="http://en.wikipedia.org/wiki/Eigenface">Eigenfaces</a> and thought it would be fun to apply the same idea to Mega Man sprites.
</p>



<h3>Setup and prep</h3>
<p>
Like most machine learning tasks, be it nlp or cv, the first thing I
was going to need was a corpus of Mega Man sprites.  And just like all
interesting data projects, this was the tedious a time consuming
part. I started with sprite sheets from <a href="http://www.sprites-inc.co.uk/">Sprites Inc</a> and put together a set of around 70 sprites that were roughly centered and were all 32x32 pixels.  Some Mega Man character sprites fit nicely into this space but others require a bit of guessing to find a good place to crop.
</p>



<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/airman.png"
     alt="airman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/blademan.png"
     alt="blademan">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/bombman.png" alt="bombman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/brightman.png" alt="brightman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/bubbleman.png" alt="bubbleman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/chargeman.png" alt="chargeman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/chillman.png"
     alt="chillman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/commandoman.png"
     alt="commandoman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/concreteman.png" alt="concreteman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/crashman.png"
     alt="crashman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/crystalman.png"
     alt="crystalman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/cutsman.png" alt="cutsman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/diveman.png" alt="diveman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/drillman.png"
     alt="drillman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/duo.png"
     alt="duo">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/dustman.png"
     alt="dustman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/elecman.png" alt="elecman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/fireman.png" alt="fireman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/flashman.png" alt="flashman">
<img src="https://raw.github.com/willkurt/EigenMan/master/original_sprites/galaxyman.png" alt="galaxyman">


<p>
The next step was to automatically convert these images to grayscale
using the Python Imaging Library (PIL).  This was necessary since the
color data really ends up adding a lot of noise to what we’re trying
to discover.  Doing this with PIL was dead simple
</p>

<pre><code>Image.open(infile).convert('L').save(outfile)
</code></pre>

<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/airman.png"
     alt="airman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/blademan.png" alt="blademan">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/bombman.png" alt="bombman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/brightman.png" alt="brightman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/bubbleman.png" alt="bubbleman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/chargeman.png" alt="chargeman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/chillman.png" alt="chillman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/commandoman.png" alt="commandoman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/concreteman.png" alt="concreteman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/crashman.png" alt="crashman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/crystalman.png" alt="crystalman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/cutsman.png" alt="cutsman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/diveman.png" alt="diveman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/drillman.png" alt="drillman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/duo.png" alt="duo">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/dustman.png" alt="dustman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/elecman.png" alt="elecman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/fireman.png"
     alt="fireman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/flashman.png" alt="flashman">
<img src="https://raw.github.com/willkurt/EigenMan/master/processed_sprites/galaxyman.png" alt="galaxyman">

<p>
The key to processing the images from here on is just to think of a 2 dimensional grayscale picture as a single vector of grayscale values.  Seeing an image as being a 32x32 matrix is essential for humans to understanding what the image is, but from a computational standpoint a single 1024 element vector is the same information.  This allows us to create a single matrix which contains n rows of and 1024 columns (where n is the number of sprites we have).
</p>

<pre><code>for sprite in sprite_files:
    i = array(Image.open(sprite)).flatten()
    images.append(i)

I = array(images)
</code></pre>
<p>
Using a few basic functions and data structures from Numpy it is very easy to create our matrix of Mega Man sprites.
</p>

<h3>Principal component analysis and Eigen Man</h3>

<p>
Okay now that we have a matrix this problem can be treated just like
any other machine learning problem! To get the ‘essence’ of all the
Mega Man sprites I use Principal Component Analysis (PCA).  The most
high level way to understand PCA is that it allows us to project a higher dimensionality space into a lower one.  What we end up with are ‘Principal Components’ which tell us the fundamental directions of the matrix in decreasing order of importance.  In short, this is exactly what I wanted in the first place, this will provide me with the ‘essence’ of the corpus of megaman sprites.
</p>
<pre><code>U,S,V = linalg.svd(I)
</code></pre>
<p>
To perform PCA I’m just using a technique from linear algebra called ‘Singular Value Decomposition’ (SVD).  This operation gives us a bunch of data but what we really care about are the values in V (which are the eigenvectors of the covariance matrix ordered by their eigenvalues, which is more than you probably want to know if you don’t already understand pca). V is a matrix of our principal components in order or importance.
</p>
<pre><code>image_scaled = (abs(V[0]/max(abs(V[0])))*255)
</code></pre>
<p>
We have to do a little trick to coax the principal component into a
sane image, but once we do we can see what "Eigen Man" looks like
(scaled up so you can see him better)!
</p>
<img src="https://raw.github.com/willkurt/EigenMan/master/final/eigen_0_large.png"
     alt="Eigen Man">
<p>
here's what first 4 principal components actually look like:
</p>

<img src="https://raw.github.com/willkurt/EigenMan/master/final/eigen_0.png"
     alt="PCA 1">
<img src="https://raw.github.com/willkurt/EigenMan/master/final/eigen_1.png"
     alt="PCA 2">
<img src="https://raw.github.com/willkurt/EigenMan/master/final/eigen_2.png"
     alt="PCA 3">
<img src="https://raw.github.com/willkurt/EigenMan/master/final/eigen_3.png"
     alt="PCA 4">

<p>and here they are blown up a bit</p>
<img src="https://raw.github.com/willkurt/EigenMan/master/final/eigen_0_large.png"
     alt="PCA 1 Larger">
<img src="https://raw.github.com/willkurt/EigenMan/master/final/eigen_1_large.png"
     alt="PCA 2 Larger">
<img src="https://raw.github.com/willkurt/EigenMan/master/final/eigen_2_large.png"
     alt="PCA 3 Larger">
<img src="https://raw.github.com/willkurt/EigenMan/master/final/eigen_3_large.png"
     alt="PCA 4 Larger">

<p>Clearly as we move away from the first we start to get stranger
  results, but it's interesting to see what the PCA did to our
  original matrix of data.</p>

<h3>Simpler can be better (or at least just as good)</h3>

<p>
Of course, while PCA is cool and all, what would have happened if we had done something much simpler and more obvious? For example taking the mean of each row in our matrix:
</p>
<pre><code>mean_image = Image.fromarray(reshape(I.mean(axis=0),[m,n]))</code></pre>
<p>
Well it turns out that the "Mean Man" is pretty darn close to what we got using PCA
</p>
<img src="https://raw.github.com/willkurt/EigenMan/master/final/mean_man_large.png"
     alt="Mean Man">

<p>
So perhaps the best take away from this experiment is to always try the simplest solution first and see what you get.  I’ve certain found that to be a surprisingly consistent truth wherever I’ve been doing any machine learning or data mining work.
</p>

<h3>Improvement?</h3>
<p>
I just wanted to make a note that the best way to improve this would
be to be more selective about about how the sprites were aligned.  For
example, it is clear that I aligned the feet more closely than the
face. Playing with the sprite alignment would be the best way to get a
better Eigen Man.
<p>
        <p>This project is maintained
        by <a href="https://github.com/willkurt">willkurt</a></p>
<p>twitter: <a href="https://twitter.com/willkurt">@willkurt</a></p>
  <p><small>"Mega Man" and all associated game sprites are copyright
  Capcom Co. Ltd</small></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>

    </div>
    <script src="javascripts/scale.fix.js"></script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-37364780-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>
